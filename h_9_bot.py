# -*- coding: utf-8 -*-
"""H_9_bot

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/173XKaJ1OOxwlV3TONC05GSPZ56cOgqhZ
"""

!pip install python-telegram-bot
!pip install torch transformers
!pip install python-telegram-bot --upgrade

from transformers import pipeline
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
import asyncio
import nest_asyncio

nest_asyncio.apply()

text_generator = pipeline(
    "text-generation",
    model="TinyLlama/TinyLlama-1.1B-Chat-v1.0",
    max_new_tokens=300,
    device="cuda",
    do_sample=True,
    temperature=0.7,
    pad_token_id=50256,
    eos_token_id=50256,
    truncation=True
)

def truncate_to_full_stop(text: str, max_chars: int) -> str:
    """
    Truncate the text to the last full stop before reaching the max character limit.
    """
    if len(text) <= max_chars:
        return text
    truncated = text[:max_chars]
    last_full_stop = truncated.rfind(".")
    if last_full_stop != -1:
        return truncated[:last_full_stop + 1]
    return truncated

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    await update.message.reply_text(
        "Hi there! Iâ€™m your AI assistant powered by TinyLlama. ðŸ˜Š\n"
        "Ask me anything or share your thoughts, and I'll do my best to help!"
    )

async def process(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    processing_message = await update.message.reply_text("Let me think...")

    try:
        user_input = f"<human>: {update.message.text}\n<assistant>:"
        generated = text_generator(user_input, num_return_sequences=1)
        full_response = generated[0]["generated_text"]

        response_text = full_response.split("<assistant>:")[-1].strip()
        if "<human>:" in response_text:
            response_text = response_text.split("<human>:")[0].strip()

        response_text = truncate_to_full_stop(response_text, max_chars=300)

        if len(response_text) < 10:
            response_text = "Hmm, could you rephrase that? I didnâ€™t quite get it."

        await processing_message.delete()
        await update.message.reply_text(response_text)

    except Exception as e:
        error_message = f"Oops, something went wrong: {str(e)}"
        await processing_message.delete()
        await update.message.reply_text(error_message)

async def main():
    TOKEN = "7626859522:AAEoBP0ysfamXjG1-7UqpvXhVBpKDYE0Uf4"
    application = Application.builder().token(TOKEN).build()

    application.add_handler(CommandHandler("start", start))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, process))

    print("Bot is running... Press Ctrl+C to stop.")
    await application.run_polling()

loop = asyncio.get_event_loop()
if not loop.is_running():
    loop.run_until_complete(main())
else:
    asyncio.ensure_future(main())

